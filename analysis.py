# analysis.py
import logging
import time
from typing import Optional, Dict

from twisted.internet.defer import Deferred
from twisted.python.failure import Failure
from twisted.internet import reactor

from ctrader_open_api.messages.OpenApiMessages_pb2 import ProtoOAGetTrendbarsReq, ProtoOAGetTrendbarsRes
from ctrader_open_api.messages.OpenApiModelMessages_pb2 import ProtoOATrendbarPeriod as TrendbarPeriod

from db import add_signal_to_history
from state import app_state
# --- –ü–û–ß–ê–¢–û–ö –ó–ú–Ü–ù: –í–∏–¥–∞–ª—è—î–º–æ –≤–∞–∂–∫—ñ —ñ–º–ø–æ—Ä—Ç–∏ –∑–≤—ñ–¥—Å–∏ ---
# import pandas as pd
# import pandas_ta as ta
# import numpy as np
# import ml_models
# --- –ö–Ü–ù–ï–¶–¨ –ó–ú–Ü–ù ---

logger = logging.getLogger("analysis")

PERIOD_MAP = { "1m": TrendbarPeriod.M1, "5m": TrendbarPeriod.M5, "15m": TrendbarPeriod.M15 }

def _sanitize(value, default=0.0):
    # --- –ü–û–ß–ê–¢–û–ö –ó–ú–Ü–ù: –Ü–º–ø–æ—Ä—Ç—É—î–º–æ pandas —Ç–∞ numpy –ª–æ–∫–∞–ª—å–Ω–æ ---
    import pandas as pd
    import numpy as np
    # --- –ö–Ü–ù–ï–¶–¨ –ó–ú–Ü–ù ---
    if value is None or pd.isna(value) or np.isinf(value):
        return default
    return float(value)

def get_market_data(client, symbol_cache, norm_pair: str, period: str, count: int) -> Deferred:
    # --- –ü–û–ß–ê–¢–û–ö –ó–ú–Ü–ù: –Ü–º–ø–æ—Ä—Ç—É—î–º–æ pandas –ª–æ–∫–∞–ª—å–Ω–æ ---
    import pandas as pd
    # --- –ö–Ü–ù–ï–¶–¨ –ó–ú–Ü–ù ---
    d = Deferred()
    symbol_details = symbol_cache.get(norm_pair)
    if not symbol_details: return d.errback(Exception(f"–ü–∞—Ä–∞ '{norm_pair}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–µ—à—ñ."))
    tf_proto = PERIOD_MAP.get(period)
    if not tf_proto: return d.errback(Exception(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {period}"))
    now = int(time.time() * 1000)
    seconds_in_period = {'1m': 60, '5m': 300, '15m': 900}.get(period, 300)
    from_ts = now - (count * seconds_in_period * 1000)
    request = ProtoOAGetTrendbarsReq(ctidTraderAccountId=client._client.account_id, symbolId=symbol_details.symbolId, period=tf_proto, fromTimestamp=from_ts, toTimestamp=now)
    deferred = client.send(request, timeout=30)
    def process_response(message):
        try:
            response = ProtoOAGetTrendbarsRes(); response.ParseFromString(message.payload)
            logger.info(f"‚úÖ Received {len(response.trendbar)} candles for {norm_pair} ({period}).")
            if not response.trendbar: return d.callback(pd.DataFrame())
            divisor = 10**5
            bars = [{'ts': pd.to_datetime(bar.utcTimestampInMinutes * 60, unit='s', utc=True), 'Open': (bar.low + bar.deltaOpen) / divisor, 'High': (bar.low + bar.deltaHigh) / divisor, 'Low': bar.low / divisor, 'Close': (bar.low + bar.deltaClose) / divisor, 'Volume': bar.volume} for bar in response.trendbar]
            df = pd.DataFrame(bars); d.callback(df.sort_values(by='ts').reset_index(drop=True))
        except Exception as e: d.errback(e)
    deferred.addCallbacks(process_response, d.errback)
    return d

def _get_prediction_from_model(df) -> Dict:
    # --- –ü–û–ß–ê–¢–û–ö –ó–ú–Ü–ù: –Ü–º–ø–æ—Ä—Ç—É—î–º–æ –≤—Å–µ –Ω–µ–æ–±—Ö—ñ–¥–Ω–µ –ª–æ–∫–∞–ª—å–Ω–æ ---
    import ml_models
    # --- –ö–Ü–ù–ï–¶–¨ –ó–ú–Ü–ù ---
    if ml_models.LGBM_MODEL is None or ml_models.SCALER is None:
        return {"score": 50, "reasons": ["ML –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞."]}

    if df.empty or len(df) < 250:
        return {"score": 50, "reasons": ["–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –≤—Å—ñ—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫."]}

    try:
        # --- –ü–û–ß–ê–¢–û–ö –ó–ú–Ü–ù: –Ü–º–ø–æ—Ä—Ç—É—î–º–æ pandas_ta –ª–æ–∫–∞–ª—å–Ω–æ ---
        import pandas_ta as ta
        # --- –ö–Ü–ù–ï–¶–¨ –ó–ú–Ü–ù ---
        df.ta.atr(length=14, append=True)
        df.ta.adx(length=14, append=True)
        df.ta.rsi(length=14, append=True)
        df.ta.ema(length=50, append=True, col_names=('EMA50',))
        df.ta.ema(length=200, append=True, col_names=('EMA200',))
        
        last_features_raw = df.iloc[[-1]]
        
        feature_map = {
            "ATRr_14": "ATR", "ADX_14": "ADX", "RSI_14": "RSI",
            "EMA50": "EMA50", "EMA200": "EMA200"
        }
        
        if not all(col in last_features_raw.columns for col in feature_map.keys()):
            return {"score": 50, "reasons": ["–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ –≤—Å—ñ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –º–æ–¥–µ–ª—ñ."]}

        features_for_model = last_features_raw[list(feature_map.keys())].copy()
        features_for_model.rename(columns=feature_map, inplace=True)

        scaled_features = ml_models.SCALER.transform(features_for_model)
        
        probabilities = ml_models.LGBM_MODEL.predict_proba(scaled_features)
        win_probability = probabilities[0][1] * 100
        
        reasons = [
            f"RSI: {_sanitize(last_features_raw['RSI_14'].iloc[0], 0):.1f}",
            f"ADX: {_sanitize(last_features_raw['ADX_14'].iloc[0], 0):.1f}",
            f"ATR: {_sanitize(last_features_raw['ATRr_14'].iloc[0], 0):.5f}",
        ]
        
        return {"score": int(win_probability), "reasons": reasons, "close": last_features_raw['Close'].iloc[0]}

    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª–ª—é: {e}")
        return {"score": 50, "reasons": ["–ü–æ–º–∏–ª–∫–∞ —Ä–æ–±–æ—Ç–∏ ML –º–æ–¥–µ–ª—ñ."]}

def _generate_verdict_from_score(score: int) -> str:
    if score >= 75: return "‚¨ÜÔ∏è –í–∏—Å–æ–∫–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å CALL"
    if score >= 60: return "‚ÜóÔ∏è –ü–æ–º—ñ—Ä–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å CALL"
    if score <= 25: return "‚¨áÔ∏è –í–∏—Å–æ–∫–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å PUT"
    if score <= 40: return "‚ÜòÔ∏è –ü–æ–º—ñ—Ä–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å PUT"
    return "üü° NEUTRAL"

def get_api_detailed_signal_data(client, symbol_cache, symbol: str, user_id: int, timeframe: str = "5m") -> Deferred:
    # --- –ü–û–ß–ê–¢–û–ö –ó–ú–Ü–ù: –Ü–º–ø–æ—Ä—Ç—É—î–º–æ pandas –ª–æ–∫–∞–ª—å–Ω–æ ---
    import pandas as pd
    # --- –ö–Ü–ù–ï–¶–¨ –ó–ú–Ü–ù ---
    final_deferred = Deferred()

    def on_data_ready(df: pd.DataFrame):
        try:
            analysis = _get_prediction_from_model(df)
            verdict = _generate_verdict_from_score(analysis['score'])
            
            response_data = {
                "pair": symbol, "price": _sanitize(analysis.get("close")),
                "verdict_text": verdict, "reasons": analysis.get("reasons", []),
                "score": analysis.get("score", 50)
            }
            
            if user_id != 0 and (analysis['score'] >= 60 or analysis['score'] <= 40):
                add_signal_to_history({
                    'user_id': user_id, 'pair': symbol,
                    'price': response_data['price'], 'bull_percentage': analysis['score']
                })
            final_deferred.callback(response_data)
        except Exception as e:
            logger.exception(f"Critical analysis error for {symbol}: {e}")
            final_deferred.errback(e)

    d = get_market_data(client, symbol_cache, symbol, timeframe, 300)
    d.addCallbacks(on_data_ready, final_deferred.errback)
    
    return final_deferred